% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
%
\documentclass[
  8pt,
  ignorenonframetext,
]{beamer}
\usepackage{pgfpages}
\setbeamertemplate{caption}[numbered]
\setbeamertemplate{caption label separator}{: }
\setbeamercolor{caption name}{fg=normal text.fg}
\beamertemplatenavigationsymbolsempty
% Prevent slide breaks in the middle of a paragraph
\widowpenalties 1 10000
\raggedbottom
\setbeamertemplate{part page}{
  \centering
  \begin{beamercolorbox}[sep=16pt,center]{part title}
    \usebeamerfont{part title}\insertpart\par
  \end{beamercolorbox}
}
\setbeamertemplate{section page}{
  \centering
  \begin{beamercolorbox}[sep=12pt,center]{part title}
    \usebeamerfont{section title}\insertsection\par
  \end{beamercolorbox}
}
\setbeamertemplate{subsection page}{
  \centering
  \begin{beamercolorbox}[sep=8pt,center]{part title}
    \usebeamerfont{subsection title}\insertsubsection\par
  \end{beamercolorbox}
}
\AtBeginPart{
  \frame{\partpage}
}
\AtBeginSection{
  \ifbibliography
  \else
    \frame{\sectionpage}
  \fi
}
\AtBeginSubsection{
  \frame{\subsectionpage}
}
\usepackage{amsmath,amssymb}
\usepackage{iftex}
\ifPDFTeX
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math} % this also loads fontspec
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
\usepackage{lmodern}
\usetheme[]{metropolis}
\usefonttheme{serif}
\ifPDFTeX\else
  % xetex/luatex font selection
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
\usepackage{xcolor}
\newif\ifbibliography
\usepackage{color}
\usepackage{fancyvrb}
\newcommand{\VerbBar}{|}
\newcommand{\VERB}{\Verb[commandchars=\\\{\}]}
\DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
% Add ',fontsize=\small' for more characters per line
\usepackage{framed}
\definecolor{shadecolor}{RGB}{248,248,248}
\newenvironment{Shaded}{\begin{snugshade}}{\end{snugshade}}
\newcommand{\AlertTok}[1]{\textcolor[rgb]{0.94,0.16,0.16}{#1}}
\newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{#1}}
\newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\BuiltInTok}[1]{#1}
\newcommand{\CharTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\CommentTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{#1}}
\newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{#1}}
\newcommand{\DecValTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\ErrorTok}[1]{\textcolor[rgb]{0.64,0.00,0.00}{\textbf{#1}}}
\newcommand{\ExtensionTok}[1]{#1}
\newcommand{\FloatTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\ImportTok}[1]{#1}
\newcommand{\InformationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\NormalTok}[1]{#1}
\newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.81,0.36,0.00}{\textbf{#1}}}
\newcommand{\OtherTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{#1}}
\newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\RegionMarkerTok}[1]{#1}
\newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.81,0.36,0.00}{\textbf{#1}}}
\newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\StringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\VariableTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\WarningTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\setlength{\emergencystretch}{3em} % prevent overfull lines
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\setcounter{secnumdepth}{-\maxdimen} % remove section numbering
\input{header_includes.tex}
\ifLuaTeX
  \usepackage{selnolig}  % disable illegal ligatures
\fi
\usepackage{bookmark}
\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\urlstyle{same}
\hypersetup{
  pdftitle={Penalize Regression R Package},
  pdfauthor={JuHyun Kang},
  hidelinks,
  pdfcreator={LaTeX via pandoc}}

\title{Penalize Regression R Package}
\subtitle{Penalize Regression R Package}
\author{JuHyun Kang}
\date{June 5, 2025}
\institute{The Three Sisters of Newton \newline School of Mathematics,
Statistics and Data Science \newline Sungshin Women's University}

\begin{document}
\frame{\titlepage}

\begin{frame}
\section{Introduction}
\end{frame}

\begin{frame}{Introduction with penalize regression}
\phantomsection\label{introduction-with-penalize-regression}
\begin{itemize}
\tightlist
\item
  A decision tree is a predictive model that splits the input space into
  regions using simple decision rules.
\end{itemize}

\begin{block}{Penalize Regression Method}
\phantomsection\label{penalize-regression-method}
\begin{itemize}
\item
  Ridge
\item
  Lasso
\item
  Elastic Net
\item
  MCP
\item
  SCAD
\end{itemize}
\end{block}
\end{frame}

\begin{frame}{Penalize Regression - Ridge}
\phantomsection\label{penalize-regression---ridge}
\[
\frac{1}{2n} || y-X \beta|| + \lambda ||\beta||_2^2
\] - Object function of ridge is strictly convex thus we can consider
convex optimization problem - Ridge method has a closed form
\end{frame}

\begin{frame}{Penalize Regression - Lasso}
\phantomsection\label{penalize-regression---lasso}
\[
\frac{1}{2n} || y-X \beta|| + \lambda ||\beta||_1
\] - Objective function of lasso is convex, not strictly convex, we can
consider convex optimization problem

\begin{itemize}
\tightlist
\item
  But it is difficult to considered as differenitable algorithms
\end{itemize}
\end{frame}

\begin{frame}{Penalize Regression - Elastic Net}
\phantomsection\label{penalize-regression---elastic-net}
\[
\frac{1}{2n} || y-X \beta|| + \lambda_1 ||\beta||_1 + \lambda_2 ||\beta||_2^2 
\] - Elastic net 은 ridge와 lasso의 penalty term을 합친 형태이다 -
Objective function of elastic net is convex, ..내용 추가
\end{frame}

\begin{frame}{Penalize Regression - Minimax Concave Penalty (MCP)}
\phantomsection\label{penalize-regression---minimax-concave-penalty-mcp}
\begin{itemize}
\tightlist
\item
  A decision tree is a predictive model that splits the input space into
  regions using simple decision rules.
\end{itemize}
\end{frame}

\begin{frame}{Penalize Regression - Smoothing Clipped Absolute Deviation
(SCAD)}
\phantomsection\label{penalize-regression---smoothing-clipped-absolute-deviation-scad}
\begin{itemize}
\tightlist
\item
  A decision tree is a predictive model that splits the input space into
  regions using simple decision rules.
\end{itemize}

\begin{block}{Algorithms}
\phantomsection\label{algorithms}
\end{block}
\end{frame}

\begin{frame}{Gradient Descent Algorithm (GD)}
\phantomsection\label{gradient-descent-algorithm-gd}
\begin{itemize}
\tightlist
\item
  A decision tree is a predictive model that splits the input space into
  regions using simple decision rules.
\end{itemize}
\end{frame}

\begin{frame}{Coordinate Descent Algorithm (CDA)}
\phantomsection\label{coordinate-descent-algorithm-cda}
\begin{itemize}
\tightlist
\item
  A decision tree is a predictive model that splits the input space into
  regions using simple decision rules.
\end{itemize}
\end{frame}

\begin{frame}{Projected Gradient Descent Algorithm (PGD)}
\phantomsection\label{projected-gradient-descent-algorithm-pgd}
\begin{itemize}
\tightlist
\item
  A decision tree is a predictive model that splits the input space into
  regions using simple decision rules.
\end{itemize}
\end{frame}

\begin{frame}{Fast Iterative Soft-Thresholding Algorithm (FISTA)}
\phantomsection\label{fast-iterative-soft-thresholding-algorithm-fista}
\begin{itemize}
\tightlist
\item
  A decision tree is a predictive model that splits the input space into
  regions using simple decision rules.
\end{itemize}
\end{frame}

\begin{frame}{Newton-Raphson Algorithm (NR)}
\phantomsection\label{newton-raphson-algorithm-nr}
\begin{itemize}
\tightlist
\item
  A decision tree is a predictive model that splits the input space into
  regions using simple decision rules.
\end{itemize}

\begin{block}{R Package}
\phantomsection\label{r-package}
\end{block}
\end{frame}

\begin{frame}[fragile]{Functions}
\phantomsection\label{functions}
\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{sq.loss }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{(y) \{}
\NormalTok{  y.bar }\OtherTok{\textless{}{-}} \FunctionTok{mean}\NormalTok{(y)}
  \FunctionTok{sum}\NormalTok{((y }\SpecialCharTok{{-}}\NormalTok{ y.bar)}\SpecialCharTok{\^{}}\DecValTok{2}\NormalTok{)}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

\begin{itemize}
\tightlist
\item
  We construct the following procedure for regression, where we apply a
  loss measure sq.loss function to the argument branch function.
\end{itemize}

\begin{block}{Q \& A}
\phantomsection\label{q-a}
\begin{center}
  {\bf {\Huge Q \& A}}
\end{center}
\end{block}

\begin{block}{}
\phantomsection\label{section}
\begin{center}
  {\bf {\Huge Thank you :)}}
\end{center}
\end{block}
\end{frame}

\end{document}
